{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import chainerrl\n",
    "import gym_rubiks\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation space: Box(6, 2, 2)\n",
      "action space: Discrete(9)\n"
     ]
    }
   ],
   "source": [
    "env = gym_rubiks.make(\"rubiks-2x2-5-v0\")\n",
    "print('observation space:', env.observation_space)\n",
    "print('action space:', env.action_space)\n",
    "\n",
    "obs = env.reset()\n",
    "env.render()\n",
    "#print('initial observation:', obs)\n",
    "\n",
    "action = env.action_space.sample()\n",
    "obs, r, done, info = env.step(action)\n",
    "#print('next observation:', obs)\n",
    "#print('reward:', r)\n",
    "#print('done:', done)\n",
    "#print('info:', info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "class QFunction(chainer.Chain):\n",
    "\n",
    "    def __init__(self, obs_size, n_actions, n_hidden_channels=9):\n",
    "        super().__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv_layers = chainer.ChainList(\n",
    "                L.ConvolutionND(2, 6, 2000,2, stride=1))\n",
    "            self.l0 = L.Linear(2000,256)\n",
    "            self.l1 = L.Linear(256, n_hidden_channels)\n",
    "\n",
    "    def __call__(self, x, test=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (ndarray or chainer.Variable): An observation\n",
    "            test (bool): a flag indicating whether it is in test mode\n",
    "        \"\"\"\n",
    "        h = x\n",
    "        for l in self.conv_layers:\n",
    "            h = F.relu(l(h))\n",
    "        h = F.relu(self.l0(h))\n",
    "        h = F.relu(self.l1(h))\n",
    "        return chainerrl.action_value.DiscreteActionValue(h)\n",
    "\n",
    "obs_size = 24\n",
    "print(obs_size)\n",
    "n_actions = env.action_space.n\n",
    "q_func = chainerrl.q_functions.FCStateQFunctionWithDiscreteAction(\n",
    "    obs_size, n_actions,\n",
    "    n_hidden_layers=2, n_hidden_channels=2000)\n",
    "#q_func = chainerrl.q_functions.DuelingDQN(n_actions,6)\n",
    "#q_func = QFunction(obs_size,n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainerrl.q_functions.state_q_functions.FCStateQFunctionWithDiscreteAction at 0x14ff7013668>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_func.to_gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Adam to optimize q_func. eps=1e-2 is for stability.\n",
    "optimizer = chainer.optimizers.Adam(eps=1e-2)\n",
    "optimizer.setup(q_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the discount factor that discounts future rewards.\n",
    "gamma = 0.95\n",
    "\n",
    "# Use epsilon-greedy for exploration\n",
    "explorer = chainerrl.explorers.ConstantEpsilonGreedy(\n",
    "    epsilon=0.3, random_action_func=env.action_space.sample)\n",
    "\n",
    "# DQN uses Experience Replay.\n",
    "# Specify a replay buffer and its capacity.\n",
    "replay_buffer = chainerrl.replay_buffer.ReplayBuffer(capacity=10 ** 6)\n",
    "\n",
    "# Since observations from CartPole-v0 is numpy.float64 while\n",
    "# Chainer only accepts numpy.float32 by default, specify\n",
    "# a converter as a feature extractor function phi.\n",
    "phi = lambda x: x.astype(np.float32, copy=False)\n",
    "\n",
    "# Now create an agent that will interact with the environment.\n",
    "agent = chainerrl.agents.DoubleDQN(\n",
    "    q_func, optimizer, replay_buffer, gamma, explorer,\n",
    "    replay_start_size=500, update_interval=1,\n",
    "    target_update_interval=100, phi=phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 100 R: -10.0 statistics: [('average_q', -0.09931802910729833), ('average_loss', 0.2986903550690484)]\n",
      "# solved: 3\n",
      "episode: 200 R: -10.0 statistics: [('average_q', -4.670691649217793), ('average_loss', 0.45458787703651327)]\n",
      "# solved: 10\n",
      "episode: 300 R: -10.0 statistics: [('average_q', -8.402759642871336), ('average_loss', 1.0090146785682381)]\n",
      "# solved: 25\n",
      "episode: 400 R: -10.0 statistics: [('average_q', -9.358780449533208), ('average_loss', 1.8668534571750335)]\n",
      "# solved: 45\n",
      "episode: 500 R: -10.0 statistics: [('average_q', -5.623351658065536), ('average_loss', 2.9940957960784873)]\n",
      "# solved: 70\n",
      "episode: 600 R: -10.0 statistics: [('average_q', 12.361717644956313), ('average_loss', 4.879309392489103)]\n",
      "# solved: 90\n",
      "episode: 700 R: 93.0 statistics: [('average_q', 37.63880908081049), ('average_loss', 5.099146608848921)]\n",
      "# solved: 133\n",
      "episode: 800 R: 92.0 statistics: [('average_q', 53.696247997463004), ('average_loss', 3.3553696429220947)]\n",
      "# solved: 180\n",
      "episode: 900 R: 95.0 statistics: [('average_q', 62.317664264862074), ('average_loss', 3.294342160290737)]\n",
      "# solved: 236\n",
      "episode: 1000 R: 98.0 statistics: [('average_q', 66.69494767032205), ('average_loss', 2.8930078579857788)]\n",
      "# solved: 283\n",
      "episode: 1100 R: 95.0 statistics: [('average_q', 70.56768395363811), ('average_loss', 2.9985045734069034)]\n",
      "# solved: 336\n",
      "episode: 1200 R: 97.0 statistics: [('average_q', 72.9974113265843), ('average_loss', 2.7299822424393527)]\n",
      "# solved: 382\n",
      "episode: 1300 R: -10.0 statistics: [('average_q', 76.16339155254207), ('average_loss', 2.9046316374310313)]\n",
      "# solved: 444\n",
      "episode: 1400 R: 97.0 statistics: [('average_q', 76.44831985830778), ('average_loss', 2.6396930229906217)]\n",
      "# solved: 492\n",
      "episode: 1500 R: -10.0 statistics: [('average_q', 76.40611216938927), ('average_loss', 2.8762904092788983)]\n",
      "# solved: 549\n",
      "episode: 1600 R: -10.0 statistics: [('average_q', 76.74642297317916), ('average_loss', 2.8421230135972677)]\n",
      "# solved: 603\n",
      "episode: 1700 R: -10.0 statistics: [('average_q', 75.88401753183555), ('average_loss', 2.767263743181543)]\n",
      "# solved: 655\n",
      "episode: 1800 R: -10.0 statistics: [('average_q', 75.80683820579159), ('average_loss', 2.8849681331040764)]\n",
      "# solved: 708\n",
      "episode: 1900 R: -10.0 statistics: [('average_q', 78.13821239958487), ('average_loss', 2.9550815400389485)]\n",
      "# solved: 779\n",
      "episode: 2000 R: -10.0 statistics: [('average_q', 76.90183837933634), ('average_loss', 2.7466973511021133)]\n",
      "# solved: 831\n",
      "episode: 2100 R: 98.0 statistics: [('average_q', 78.60013657774475), ('average_loss', 3.0336205894852344)]\n",
      "# solved: 892\n",
      "episode: 2200 R: 97.0 statistics: [('average_q', 78.80683628329878), ('average_loss', 2.6193476886007994)]\n",
      "# solved: 958\n",
      "episode: 2300 R: -10.0 statistics: [('average_q', 78.23181394367211), ('average_loss', 2.903915566888781)]\n",
      "# solved: 1018\n",
      "episode: 2400 R: 100.0 statistics: [('average_q', 77.74071274424652), ('average_loss', 2.833301029351952)]\n",
      "# solved: 1084\n",
      "episode: 2500 R: 98.0 statistics: [('average_q', 79.33467155829253), ('average_loss', 2.6647933846614467)]\n",
      "# solved: 1144\n",
      "episode: 2600 R: -10.0 statistics: [('average_q', 80.13797672406022), ('average_loss', 2.8240439435865663)]\n",
      "# solved: 1207\n",
      "episode: 2700 R: -10.0 statistics: [('average_q', 78.78808464875915), ('average_loss', 2.5008634202639604)]\n",
      "# solved: 1264\n",
      "episode: 2800 R: -10.0 statistics: [('average_q', 79.00042119004075), ('average_loss', 2.5973177944551358)]\n",
      "# solved: 1329\n",
      "episode: 2900 R: -10.0 statistics: [('average_q', 78.38118924622412), ('average_loss', 2.6065780525812956)]\n",
      "# solved: 1386\n",
      "episode: 3000 R: 99.0 statistics: [('average_q', 80.00665460061633), ('average_loss', 2.7805060202942498)]\n",
      "# solved: 1452\n",
      "episode: 3100 R: 99.0 statistics: [('average_q', 79.36983240416266), ('average_loss', 2.53380818630578)]\n",
      "# solved: 1512\n",
      "episode: 3200 R: 100.0 statistics: [('average_q', 80.24864482551415), ('average_loss', 2.7069296084633327)]\n",
      "# solved: 1576\n",
      "episode: 3300 R: 96.0 statistics: [('average_q', 80.24185986586974), ('average_loss', 2.6704943181456926)]\n",
      "# solved: 1640\n",
      "episode: 3400 R: 92.0 statistics: [('average_q', 80.6397307528154), ('average_loss', 2.5563925029989862)]\n",
      "# solved: 1698\n",
      "episode: 3500 R: 95.0 statistics: [('average_q', 80.84902679208369), ('average_loss', 2.387861052440315)]\n",
      "# solved: 1761\n",
      "episode: 3600 R: -10.0 statistics: [('average_q', 80.6175562659401), ('average_loss', 2.3212194760636677)]\n",
      "# solved: 1823\n",
      "episode: 3700 R: 95.0 statistics: [('average_q', 80.258326358525), ('average_loss', 2.5271162869226025)]\n",
      "# solved: 1891\n",
      "episode: 3800 R: -10.0 statistics: [('average_q', 80.39701188247791), ('average_loss', 2.618050009730358)]\n",
      "# solved: 1956\n",
      "episode: 3900 R: 97.0 statistics: [('average_q', 81.62699125505085), ('average_loss', 2.499293016223708)]\n",
      "# solved: 2028\n",
      "episode: 4000 R: -10.0 statistics: [('average_q', 81.03739881516717), ('average_loss', 2.352616341699841)]\n",
      "# solved: 2099\n",
      "Finished.\n",
      "2099\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_episodes = 4000\n",
    "max_episode_len = 10\n",
    "n_done = 0\n",
    "for i in range(1, n_episodes + 1):\n",
    "    obs = env.reset()\n",
    "    reward = 0\n",
    "    done = False\n",
    "    R = 0  # return (sum of rewards)\n",
    "    t = 0  # time step\n",
    "    while not done and t < max_episode_len:\n",
    "        # Uncomment to watch the behaviour\n",
    "        # env.render()\n",
    "        action = agent.act_and_train(obs, reward)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        R += reward\n",
    "        t += 1\n",
    "        n_done += done\n",
    "#         if done:\n",
    "#             print('solved on:',i)\n",
    "#             print('earned :', R)\n",
    "    if i % 100 == 0:\n",
    "        print('episode:', i,\n",
    "              'R:', R,\n",
    "              'statistics:', agent.get_statistics())\n",
    "        print('# solved:',n_done)\n",
    "    agent.stop_episode_and_train(obs, reward, done)\n",
    "print('Finished.')\n",
    "print(n_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test episode: 0 R: 98.0\n",
      "test episode: 1 R: 97.0\n",
      "test episode: 2 R: 99.0\n",
      "test episode: 3 R: 99.0\n",
      "test episode: 4 R: 100.0\n",
      "test episode: 5 R: 97.0\n",
      "test episode: 6 R: 99.0\n",
      "test episode: 7 R: 97.0\n",
      "test episode: 8 R: 96.0\n",
      "test episode: 9 R: 97.0\n",
      "test episode: 10 R: -20.0\n",
      "test episode: 11 R: 97.0\n",
      "test episode: 12 R: 99.0\n",
      "test episode: 13 R: 98.0\n",
      "test episode: 14 R: 96.0\n",
      "test episode: 15 R: 98.0\n",
      "test episode: 16 R: -20.0\n",
      "test episode: 17 R: 98.0\n",
      "test episode: 18 R: 96.0\n",
      "test episode: 19 R: 98.0\n",
      "test episode: 20 R: 98.0\n",
      "test episode: 21 R: 99.0\n",
      "test episode: 22 R: 98.0\n",
      "test episode: 23 R: 98.0\n",
      "test episode: 24 R: 97.0\n",
      "test episode: 25 R: 96.0\n",
      "test episode: 26 R: 100.0\n",
      "test episode: 27 R: 98.0\n",
      "test episode: 28 R: 98.0\n",
      "test episode: 29 R: 98.0\n",
      "test episode: 30 R: 98.0\n",
      "test episode: 31 R: 99.0\n",
      "test episode: 32 R: 98.0\n",
      "test episode: 33 R: 98.0\n",
      "test episode: 34 R: -20.0\n",
      "test episode: 35 R: 95.0\n",
      "test episode: 36 R: 99.0\n",
      "test episode: 37 R: 98.0\n",
      "test episode: 38 R: 97.0\n",
      "test episode: 39 R: 99.0\n",
      "test episode: 40 R: 98.0\n",
      "test episode: 41 R: 97.0\n",
      "test episode: 42 R: -20.0\n",
      "test episode: 43 R: 97.0\n",
      "test episode: 44 R: 98.0\n",
      "test episode: 45 R: 96.0\n",
      "test episode: 46 R: -20.0\n",
      "test episode: 47 R: -20.0\n",
      "test episode: 48 R: 97.0\n",
      "test episode: 49 R: 98.0\n",
      "test episode: 50 R: 96.0\n",
      "test episode: 51 R: 100.0\n",
      "test episode: 52 R: -20.0\n",
      "test episode: 53 R: 98.0\n",
      "test episode: 54 R: 98.0\n",
      "test episode: 55 R: 97.0\n",
      "test episode: 56 R: 98.0\n",
      "test episode: 57 R: -20.0\n",
      "test episode: 58 R: 97.0\n",
      "test episode: 59 R: 99.0\n",
      "test episode: 60 R: 98.0\n",
      "test episode: 61 R: 99.0\n",
      "test episode: 62 R: 99.0\n",
      "test episode: 63 R: 95.0\n",
      "test episode: 64 R: -20.0\n",
      "test episode: 65 R: 98.0\n",
      "test episode: 66 R: 97.0\n",
      "test episode: 67 R: 97.0\n",
      "test episode: 68 R: 96.0\n",
      "test episode: 69 R: 99.0\n",
      "test episode: 70 R: 96.0\n",
      "test episode: 71 R: 96.0\n",
      "test episode: 72 R: 96.0\n",
      "test episode: 73 R: 98.0\n",
      "test episode: 74 R: -20.0\n",
      "test episode: 75 R: 98.0\n",
      "test episode: 76 R: 100.0\n",
      "test episode: 77 R: 97.0\n",
      "test episode: 78 R: 99.0\n",
      "test episode: 79 R: 99.0\n",
      "test episode: 80 R: 98.0\n",
      "test episode: 81 R: 97.0\n",
      "test episode: 82 R: 99.0\n",
      "test episode: 83 R: 97.0\n",
      "test episode: 84 R: 98.0\n",
      "test episode: 85 R: -20.0\n",
      "test episode: 86 R: 97.0\n",
      "test episode: 87 R: 99.0\n",
      "test episode: 88 R: 99.0\n",
      "test episode: 89 R: -20.0\n",
      "test episode: 90 R: 99.0\n",
      "test episode: 91 R: 99.0\n",
      "test episode: 92 R: 96.0\n",
      "test episode: 93 R: 98.0\n",
      "test episode: 94 R: 98.0\n",
      "test episode: 95 R: 99.0\n",
      "test episode: 96 R: 96.0\n",
      "test episode: 97 R: 97.0\n",
      "test episode: 98 R: 97.0\n",
      "test episode: 99 R: 98.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    R = 0\n",
    "    t = 0\n",
    "    while not done and t < 20:\n",
    "        env.render()\n",
    "        action = agent.act(obs)\n",
    "        obs, r, done, _ = env.step(action)\n",
    "        R += r\n",
    "        t += 1\n",
    "    print('test episode:', i, 'R:', R)\n",
    "    agent.stop_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save('agent5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.load('agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test episode: 0 R: 98.0\n",
      "test episode: 1 R: 97.0\n",
      "test episode: 2 R: 98.0\n",
      "test episode: 3 R: 99.0\n",
      "test episode: 4 R: 100.0\n",
      "test episode: 5 R: 99.0\n",
      "test episode: 6 R: 97.0\n",
      "test episode: 7 R: 98.0\n",
      "test episode: 8 R: 99.0\n",
      "test episode: 9 R: 99.0\n",
      "test episode: 10 R: 98.0\n",
      "test episode: 11 R: 97.0\n",
      "test episode: 12 R: 95.0\n",
      "test episode: 13 R: 99.0\n",
      "test episode: 14 R: 96.0\n",
      "test episode: 15 R: 99.0\n",
      "test episode: 16 R: 96.0\n",
      "test episode: 17 R: 97.0\n",
      "test episode: 18 R: 98.0\n",
      "test episode: 19 R: 98.0\n",
      "test episode: 20 R: 98.0\n",
      "test episode: 21 R: 98.0\n",
      "test episode: 22 R: 98.0\n",
      "test episode: 23 R: 97.0\n",
      "test episode: 24 R: -20.0\n",
      "test episode: 25 R: 100.0\n",
      "test episode: 26 R: 98.0\n",
      "test episode: 27 R: 98.0\n",
      "test episode: 28 R: 98.0\n",
      "test episode: 29 R: 97.0\n",
      "test episode: 30 R: 97.0\n",
      "test episode: 31 R: 98.0\n",
      "test episode: 32 R: -20.0\n",
      "test episode: 33 R: 98.0\n",
      "test episode: 34 R: 98.0\n",
      "test episode: 35 R: 99.0\n",
      "test episode: 36 R: 97.0\n",
      "test episode: 37 R: 97.0\n",
      "test episode: 38 R: 96.0\n",
      "test episode: 39 R: 97.0\n",
      "test episode: 40 R: -20.0\n",
      "test episode: 41 R: 100.0\n",
      "test episode: 42 R: 98.0\n",
      "test episode: 43 R: 99.0\n",
      "test episode: 44 R: 95.0\n",
      "test episode: 45 R: 98.0\n",
      "test episode: 46 R: 99.0\n",
      "test episode: 47 R: 98.0\n",
      "test episode: 48 R: 94.0\n",
      "test episode: 49 R: 100.0\n",
      "test episode: 50 R: 99.0\n",
      "test episode: 51 R: 98.0\n",
      "test episode: 52 R: 99.0\n",
      "test episode: 53 R: 94.0\n",
      "test episode: 54 R: 97.0\n",
      "test episode: 55 R: 99.0\n",
      "test episode: 56 R: 98.0\n",
      "test episode: 57 R: 99.0\n",
      "test episode: 58 R: 96.0\n",
      "test episode: 59 R: -20.0\n",
      "test episode: 60 R: -20.0\n",
      "test episode: 61 R: 97.0\n",
      "test episode: 62 R: 99.0\n",
      "test episode: 63 R: 96.0\n",
      "test episode: 64 R: 99.0\n",
      "test episode: 65 R: 95.0\n",
      "test episode: 66 R: 100.0\n",
      "test episode: 67 R: 97.0\n",
      "test episode: 68 R: 98.0\n",
      "test episode: 69 R: 96.0\n",
      "test episode: 70 R: 99.0\n",
      "test episode: 71 R: 95.0\n",
      "test episode: 72 R: 99.0\n",
      "test episode: 73 R: 99.0\n",
      "test episode: 74 R: 98.0\n",
      "test episode: 75 R: 99.0\n",
      "test episode: 76 R: 96.0\n",
      "test episode: 77 R: 96.0\n",
      "test episode: 78 R: -20.0\n",
      "test episode: 79 R: 98.0\n",
      "test episode: 80 R: 98.0\n",
      "test episode: 81 R: 98.0\n",
      "test episode: 82 R: 97.0\n",
      "test episode: 83 R: 98.0\n",
      "test episode: 84 R: 97.0\n",
      "test episode: 85 R: 98.0\n",
      "test episode: 86 R: 97.0\n",
      "test episode: 87 R: 96.0\n",
      "test episode: 88 R: 96.0\n",
      "test episode: 89 R: 91.0\n",
      "test episode: 90 R: 96.0\n",
      "test episode: 91 R: 98.0\n",
      "test episode: 92 R: 99.0\n",
      "test episode: 93 R: -20.0\n",
      "test episode: 94 R: 96.0\n",
      "test episode: 95 R: 98.0\n",
      "test episode: 96 R: 97.0\n",
      "test episode: 97 R: 100.0\n",
      "test episode: 98 R: 95.0\n",
      "test episode: 99 R: 95.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    R = 0\n",
    "    t = 0\n",
    "    while not done and t < 20:\n",
    "        env.render()\n",
    "        action = agent.act(obs)\n",
    "        obs, r, done, _ = env.step(action)\n",
    "        R += r\n",
    "        t += 1\n",
    "    print('test episode:', i, 'R:', R)\n",
    "    agent.stop_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
